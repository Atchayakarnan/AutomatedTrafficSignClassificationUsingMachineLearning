import numpy as np import cv2 
from tensorflow import keras 
threshold = 0.75  # THRESHOLD 
font = cv2.FONT_HERSHEY_SIMPLEX model = keras.models.load_model( "D:/Road_sign/traffif_sign_model.h5" 
) 
def preprocess_img( imgBGR, erode_dilate=True 
):  # pre-processing fro detect signs in  image. 
rows, cols, _ = imgBGR.shape 
imgHSV = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2HSV) 
Bmin = np.array([100, 43, 46]) 
Bmax = np.array([124, 255, 255]) 
img_Bbin = cv2.inRange(imgHSV, Bmin, Bmax) 
Rmin1 = np.array([0, 43, 46]) 
Rmax1 = np.array([10, 255, 255]) 
img_Rbin1 = cv2.inRange(imgHSV, Rmin1, Rmax1) 
Rmin2 = np.array([156, 43, 46]) 
Rmax2 = np.array([180, 255, 255]) img_Rbin2 = cv2.inRange(imgHSV, Rmin2, Rmax2) img_Rbin = np.maximum(img_Rbin1, img_Rbin2) img_bin = np.maximum(img_Bbin, img_Rbin) 
if erode_dilate is True: kernelErosion = np.ones((3, 3), np.uint8) kernelDilation = np.ones((3, 3), np.uint8) img_bin = cv2.erode(img_bin, kernelErosion, iterations=2) img_bin = cv2.dilate(img_bin, kernelDilation, iterations=2) 
return img_bin 
def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0): 
rects = [] 
contours, _ = cv2.findContours( 
img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE 
) 
if len(contours) == 0: return rects 
 
max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area for contour in contours: area = cv2.contourArea(contour) if area >= min_area and area <= max_area: x, y, w, h = cv2.boundingRect(contour) if 1.0 * w / h < wh_ratio and 1.0 * h / w < wh_ratio: rects.append([x, y, w, h]) return rects 
def grayscale(img): 
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) return img 
def equalize(img): img = cv2.equalizeHist(img) return img 
def preprocessing(img): img = grayscale(img) img = equalize(img) img = img / 255 
return img  
def getClassName(classNos): class_names = [ "Speed Limit 20 km/h", 
"Speed Limit 30 km/h", 
"Speed Limit 50 km/h", 
"Speed Limit 60 km/h", 
"Speed Limit 70 km/h", 
"Speed Limit 80 km/h", 
"End of Speed Limit 80 km/h", 
"Speed Limit 100 km/h", 
"Speed Limit 120 km/h", 
"No passing", 
"No passing for vehicles over 3.5 metric tons", 
"Right-of-way at the next intersection", 
"Priority road", 
"Yield", 
"Stop", 
"No vehicles", 
"Vehicles over 3.5 metric tons prohibited", 
"No entry", 
"General caution", 
"Dangerous curve to the left", 
"Dangerous curve to the right", 
"Double curve", 
"Bumpy road", 
"Slippery road", 
"Road narrows on the right", 
"Road work", 
"Traffic signals", 
"Pedestrians", 
"Children crossing", 
"Bicycles crossing", 
"Beware of ice/snow", 
"Wild animals crossing", 
"End of all speed and passing limits", 
"Turn right ahead", 
"Turn left ahead", 
"Ahead only", 
"Go straight or right", 
"Go straight or left", 
"Keep right", 
"Keep left", 
"Roundabout mandatory", 
"End of no passing", 
"End of no passing by vehicles over 3.5 metric tons", 
] 
if isinstance(classNos, (int, np.int64)): 
return class_names[classNos] elif isinstance(classNos, (list, np.ndarray)): return [class_names[c] for c in classNos] else: 
raise ValueError("Invalid input type for classNos") 
# Example usage: 
# single_class_name = getClassName(3) 
# multiple_class_names = getClassName([1, 5, 8]) 
if __name__ == "__main__": 
cap = cv2.VideoCapture(0) 
cols = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) 
rows = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) 
while 1: ret, img = cap.read() img_bin = preprocess_img(img, False) cv2.imshow("bin image", img_bin) min_area = img_bin.shape[0] * img.shape[1] / (25 * 25) rects = contour_detect(img_bin, min_area=min_area)  # get x,y,h and w. img_bbx = img.copy() for rect in rects: xc = int(rect[0] + rect[2] / 2) yc = int(rect[1] + rect[3] / 2) 
size = max(rect[2], rect[3]) x1 = max(0, int(xc - size / 2)) y1 = max(0, int(yc - size / 2)) x2 = min(cols, int(xc + size / 2)) 
y2 = min(rows, int(yc + size / 2)) 
# rect[2] is width and rect[3] for height if ( 
rect[2] > 100 and rect[3] > 100 
):  # only detect those signs whose height and width >100 cv2.rectangle( img_bbx, 
(rect[0], rect[1]), 
(rect[0] + rect[2], rect[1] + rect[3]), 
(0, 0, 255), 
2, 
) 
crop_img = np.asarray(img[y1:y2, x1:x2]) crop_img = cv2.resize(crop_img, (32, 32)) crop_img = preprocessing(crop_img) cv2.imshow("afterprocessing", crop_img) crop_img = crop_img.reshape( 
1, 32, 32, 1 
)  # (1,32,32) after reshape it become (1,32,32,1) predictions = model.predict(crop_img)  # make predicion classIndex = model.predict_step(crop_img) probabilityValue = np.amax(predictions) 
# ... 
# ... 
if probabilityValue > threshold: 
# Extract the class index from the TensorFlow tensor classIndex = np.argmax(predictions[0]) 
# write class name on the output screen print("classIndex type:", type(classIndex))  # Add this line print("classIndex value:", classIndex)  # Add this line print("The sign is:", getClassName(classIndex)) cv2.putText( img_bbx, 
str(classIndex) + " " + str(getClassName(classIndex)), 
(rect[0], rect[1] - 10), font, 0.75, 
(0, 0, 255), 
2, 
cv2.LINE_AA, 
) 
# write probability value on the output screen cv2.putText( img_bbx, 
str(round(probabilityValue * 100, 2)) + "%", 
(rect[0], rect[1] - 40), font, 0.75, 
(0, 0, 255), 
2, 
cv2.LINE_AA, 
) 
# ... 
 
# ... 
 
cv2.imshow("detect result", img_bbx) if cv2.waitKey(1) & 0xFF == ord("q"):  # q for quit break 
cap.release() cv2.destroyAllWindows() Decte.py 
import cv2 import numpy as np 
from tensorflow import keras 
 
threshold = 0.75  # THRESHOLD 
font = cv2.FONT_HERSHEY_SIMPLEX model = keras.models.load_model( "D:/Road_sign/traffif_sign_model.h5" 
) 
def preprocess_img(imgBGR, erode_dilate=True): rows, cols, _ = imgBGR.shape 
imgHSV = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2HSV) 
Bmin = np.array([100, 43, 46]) 
Bmax = np.array([124, 255, 255]) 
img_Bbin = cv2.inRange(imgHSV, Bmin, Bmax) 
 
Rmin1 = np.array([0, 43, 46]) 
Rmax1 = np.array([10, 255, 255]) 
img_Rbin1 = cv2.inRange(imgHSV, Rmin1, Rmax1) 
 
Rmin2 = np.array([156, 43, 46]) 
Rmax2 = np.array([180, 255, 255]) img_Rbin2 = cv2.inRange(imgHSV, Rmin2, Rmax2) img_Rbin = np.maximum(img_Rbin1, img_Rbin2) 
img_bin = np.maximum(img_Bbin, img_Rbin) 
 
if erode_dilate: kernelErosion = np.ones((3, 3), np.uint8) kernelDilation = np.ones((3, 3), np.uint8) img_bin = cv2.erode(img_bin, kernelErosion, iterations=2) img_bin = cv2.dilate(img_bin, kernelDilation, iterations=2) 
 
return img_bin 
 
 
def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0): 
rects = [] 
contours, _ = cv2.findContours( 
img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE 
) 
if len(contours) == 0: 
return rects 
 
max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area for contour in contours: area = cv2.contourArea(contour) if area >= min_area and area <= max_area: x, y, w, h = cv2.boundingRect(contour) if 1.0 * w / h < wh_ratio and 1.0 * h / w < wh_ratio: rects.append([x, y, w, h]) return rects 
 
 
def grayscale(img): 
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) return img 
 
 
def equalize(img): img = cv2.equalizeHist(img) return img 
 
 
def preprocessing(img): img = grayscale(img) img = equalize(img) img = img / 255 
return img 
 
 
def get_class_name(classNo): if classNo == 0: 
return "Speed Limit 20 km/h" elif classNo == 1: 
return "Speed Limit 30 km/h" elif classNo == 2: 
return "Speed Limit 50 km/h" elif classNo == 3: 
return "Speed Limit 60 km/h" elif classNo == 4: 
return "Speed Limit 70 km/h" elif classNo == 5: 
return "Speed Limit 80 km/h" elif classNo == 6: 
return "End of Speed Limit 80 km/h" elif classNo == 7: 
return "Speed Limit 100 km/h" elif classNo == 8: 
return "Speed Limit 120 km/h" elif classNo == 9: return "No passing" elif classNo == 10: 
return "No passing for vechiles over 3.5 metric tons" elif classNo == 11: 
return "Right-of-way at the next intersection" elif classNo == 12: return "Priority road" elif classNo == 13: return "Yield" elif classNo == 14: return "Stop" elif classNo == 15: return "No vechiles" elif classNo == 16: 
return "Vechiles over 3.5 metric tons prohibited" elif classNo == 17: return "No entry" elif classNo == 18: return "General caution" elif classNo == 19: 
return "Dangerous curve to the left" elif classNo == 20: 
return "Dangerous curve to the right" elif classNo == 21: return "Double curve" elif classNo == 22: return "Bumpy road" elif classNo == 23: return "Slippery road" elif classNo == 24: 
return "Road narrows on the right" elif classNo == 25: return "Road work" elif classNo == 26: return "Traffic signals" elif classNo == 27: return "Pedestrians" elif classNo == 28: 
return "Children crossing" elif classNo == 29: 
return "Bicycles crossing" elif classNo == 30: 
return "Beware of ice/snow" elif classNo == 31: 
return "Wild animals crossing" 
elif classNo == 32: 
return "End of all speed and passing limits" elif classNo == 33: 
return "Turn right ahead" elif classNo == 34: 
return "Turn left ahead" elif classNo == 35: return "Ahead only" elif classNo == 36: 
return "Go straight or right" elif classNo == 37: 
return "Go straight or left" elif classNo == 38: return "Keep right" elif classNo == 39: return "Keep left" elif classNo == 40: 
return "Roundabout mandatory" elif classNo == 41: 
return "End of no passing" elif classNo == 42: return "End of no passing by vechiles over 3.5 metric tons" 
 
 
if __name__ == "__main__": 
# img_path = 
r"C:\Users\ADMIN\Desktop\Road_sign\road\360_F_191083470_VtFAYAD2WjBIyvFk80Ll r7sJ0hAFhCv3.jpg" 
# Replace with the path to your image img_path = input("Enter the path to the image: ") 
img = cv2.imread(img_path) 
 
img_bin = preprocess_img(img, False) 
cv2.imshow("bin image", img_bin) 
 
min_area = img_bin.shape[0] * img.shape[1] / (25 * 25) rects = contour_detect(img_bin, min_area=min_area) img_bbx = img.copy() 
 
for rect in rects: xc = int(rect[0] + rect[2] / 2) yc = int(rect[1] + rect[3] / 2) size = max(rect[2], rect[3]) x1 = max(0, int(xc - size / 2)) y1 = max(0, int(yc - size / 2)) x2 = min(img.shape[1], int(xc + size / 2)) y2 = min(img.shape[0], int(yc + size / 2)) if rect[2] > 100 and rect[3] > 100: cv2.rectangle( 
img_bbx, 
(rect[0], rect[1]), 
(rect[0] + rect[2], rect[1] + rect[3]), 
(0, 0, 255), 
2, 
) 
 
crop_img = np.asarray(img[y1:y2, x1:x2]) crop_img = cv2.resize(crop_img, (32, 32)) crop_img = preprocessing(crop_img) crop_img = crop_img.reshape(1, 32, 32, 1) 
 
predictions = model.predict(crop_img) class_index = np.argmax(predictions) probability_value = np.amax(predictions) print("Class Index:", class_index) print("Probability Value:", probability_value) print("The sign is:", get_class_name(class_index)) if probability_value > threshold: cv2.putText( img_bbx, 
str(class_index) + " " + get_class_name(class_index), 
(rect[0], rect[1] - 10), font, 0.75, 
(0, 0, 255), 
2, 
cv2.LINE_AA, 
) 
cv2.putText( img_bbx, 
str(round(probability_value * 100, 2)) + "%", 
(rect[0], rect[1] - 40), font, 0.75, 
(0, 0, 255), 
2, 
cv2.LINE_AA, 
) 
cv2.imshow("detect result", img_bbx) cv2.waitKey(0)  # Add this line to wait for a key press 
cv2.destroyAllWindows() 
 
 
 
decte_1.py 
 
import cv2 import numpy as np 
from tensorflow import keras 
 
threshold = 0.75  # THRESHOLD 
font = cv2.FONT_HERSHEY_SIMPLEX model = keras.models.load_model( 
"C:/Users/ADMIN/Desktop/Road_sign/road/traffif_sign_model.h5" 
) 
 
 
def preprocess_img(imgBGR, erode_dilate=True): rows, cols, _ = imgBGR.shape 
imgHSV = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2HSV) 
Bmin = np.array([100, 43, 46]) 
Bmax = np.array([124, 255, 255]) 
img_Bbin = cv2.inRange(imgHSV, Bmin, Bmax) 
 
Rmin1 = np.array([0, 43, 46]) 
Rmax1 = np.array([10, 255, 255]) 
img_Rbin1 = cv2.inRange(imgHSV, Rmin1, Rmax1) 
 
Rmin2 = np.array([156, 43, 46]) 
Rmax2 = np.array([180, 255, 255]) img_Rbin2 = cv2.inRange(imgHSV, Rmin2, Rmax2) img_Rbin = np.maximum(img_Rbin1, img_Rbin2) 
img_bin = np.maximum(img_Bbin, img_Rbin) 
 
if erode_dilate: kernelErosion = np.ones((3, 3), np.uint8) kernelDilation = np.ones((3, 3), np.uint8) img_bin = cv2.erode(img_bin, kernelErosion, iterations=2) img_bin = cv2.dilate(img_bin, kernelDilation, iterations=2) 
 
return img_bin 
 
 
def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0): 
rects = [] 
contours, _ = cv2.findContours( 
img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE 
) 
if len(contours) == 0: return rects 
 
max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area for contour in contours: area = cv2.contourArea(contour) if area >= min_area and area <= max_area: x, y, w, h = cv2.boundingRect(contour) if 1.0 * w / h < wh_ratio and 1.0 * h / w < wh_ratio: rects.append([x, y, w, h]) return rects 
 
 
def grayscale(img): 
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) return img 
 
 
def equalize(img): img = cv2.equalizeHist(img) return img 
 
 
def preprocessing(img): img = grayscale(img) img = equalize(img) img = img / 255 
return img 
 
 
def get_class_name(classNo): if classNo == 0: 
return "Speed Limit 20 km/h" elif classNo == 1: 
return "Speed Limit 30 km/h" elif classNo == 2: 
return "Speed Limit 50 km/h" elif classNo == 3: 
return "Speed Limit 60 km/h" elif classNo == 4: 
return "Speed Limit 70 km/h" elif classNo == 5: 
return "Speed Limit 80 km/h" elif classNo == 6: return "End of Speed Limit 80 km/h" elif classNo == 7: 
return "Speed Limit 100 km/h" elif classNo == 8: 
return "Speed Limit 120 km/h" elif classNo == 9: return "No passing" elif classNo == 10: 
return "No passing for vechiles over 3.5 metric tons" elif classNo == 11: 
return "Right-of-way at the next intersection" elif classNo == 12: return "Priority road" elif classNo == 13: return "Yield" elif classNo == 14: return "Stop" elif classNo == 15: return "No vechiles" elif classNo == 16: 
return "Vechiles over 3.5 metric tons prohibited" elif classNo == 17: return "No entry" elif classNo == 18: return "General caution" elif classNo == 19: 
return "Dangerous curve to the left" elif classNo == 20: 
return "Dangerous curve to the right" elif classNo == 21: return "Double curve" elif classNo == 22: return "Bumpy road" elif classNo == 23: return "Slippery road" elif classNo == 24: 
return "Road narrows on the right" elif classNo == 25: return "Road work" elif classNo == 26: return "Traffic signals" elif classNo == 27: return "Pedestrians" elif classNo == 28: 
return "Children crossing" elif classNo == 29: 
return "Bicycles crossing" elif classNo == 30: 
return "Beware of ice/snow" elif classNo == 31: 
return "Wild animals crossing" elif classNo == 32: 
return "End of all speed and passing limits" elif classNo == 33: 
return "Turn right ahead" elif classNo == 34: 
return "Turn left ahead" elif classNo == 35: return "Ahead only" elif classNo == 36: 
return "Go straight or right" elif classNo == 37: 
return "Go straight or left" elif classNo == 38: return "Keep right" elif classNo == 39: return "Keep left" elif classNo == 40: 
return "Roundabout mandatory" elif classNo == 41: 
return "End of no passing" elif classNo == 42: return "End of no passing by vechiles over 3.5 metric tons" 
 
 
if __name__ == "__main__": 
# img_path = 
r"C:\Users\ADMIN\Desktop\Road_sign\road\360_F_191083470_VtFAYAD2WjBIyvFk80Ll r7sJ0hAFhCv3.jpg" 
# Replace with the path to your image img_path = input("Enter the path to the image: ") 
img = cv2.imread(img_path) 
 
img_bin = preprocess_img(img, False) 
cv2.imshow("bin image", img_bin) 
 
min_area = img_bin.shape[0] * img.shape[1] / (25 * 25) rects = contour_detect(img_bin, min_area=min_area) img_bbx = img.copy() 
 
for rect in rects: 
xc = int(rect[0] + rect[2] / 2) yc = int(rect[1] + rect[3] / 2) size = max(rect[2], rect[3]) x1 = max(0, int(xc - size / 2)) y1 = max(0, int(yc - size / 2)) x2 = min(img.shape[1], int(xc + size / 2)) y2 = min(img.shape[0], int(yc + size / 2)) 
 
if rect[2] > 100 and rect[3] > 100: cv2.rectangle( 
img_bbx, 
(rect[0], rect[1]), 
(rect[0] + rect[2], rect[1] + rect[3]), 
(0, 0, 255), 
2, 
) 
 
crop_img = np.asarray(img[y1:y2, x1:x2]) crop_img = cv2.resize(crop_img, (32, 32)) crop_img = preprocessing(crop_img) 
crop_img = crop_img.reshape(1, 32, 32, 1) 
 
predictions = model.predict(crop_img) class_index = np.argmax(predictions) probability_value = np.amax(predictions) print("Class Index:", class_index) print("Probability Value:", probability_value) print("The sign is:", get_class_name(class_index)) if probability_value > threshold: cv2.putText( img_bbx, 
str(class_index) + " " + get_class_name(class_index), 
(rect[0], rect[1] - 10), font, 0.75, 
(0, 0, 255), 
2, 
cv2.LINE_AA, 
) 
cv2.putText( img_bbx, 
str(round(probability_value * 100, 2)) + "%", 
(rect[0], rect[1] - 40), font, 0.75, 
(0, 0, 255), 
2, 
cv2.LINE_AA, 
) 
cv2.imshow("detect result", img_bbx) cv2.waitKey(0)  # Add this line to wait for a key press training.py 
 
#********* Libraries ******* import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential from keras.layers import Dense from keras.optimizers import Adam from keras.utils.np_utils import to_categorical from keras.layers import Dropout, Flatten 
from keras.layers.convolutional import Conv2D, MaxPooling2D import cv2 
from sklearn.model_selection import train_test_split import os import pandas as pd import random 
from keras.preprocessing.image import ImageDataGenerator 
 
path = "Train" 
labelFile = 'Train.csv' 
 
count = 0 images = [] label = [] 
classes_list = os.listdir(path) 
print("Total Classes Detected:",len(classes_list)) noOfClasses=len(classes_list) print("Importing Classes.....") for x in range (0,len(classes_list)): 
imglist = os.listdir(path+"/"+str(count)) for y in imglist: 
img = cv2.imread(path+"/"+str(count)+"/"+y) img =cv2.resize(img,(32,32)) images.append(img) label.append(count) print(count, end =" ") count +=1 print(" ") 
 
images = np.array(images) classNo = np.array(label) data=np.array(images) 
data= np.array(data).reshape(-1, 32, 32, 3) 
 
 
X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=0.2) Y_tests=y_test 
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2) 
 
print("Data Shapes") 
print("Train",end = "");print(X_train.shape,y_train.shape) 
print("Validation",end = "");print(X_validation.shape,y_validation.shape) print("Test",end = "");print(X_test.shape,y_test.shape) 
 
batch_size_val=30 steps_per_epoch_val=500 epochs_val=40 
 
data=pd.read_csv(labelFile) 
print("data shape ",data.shape,type(data)) 
num_of_samples = [] 
cols = 3 
num_classes = noOfClasses 
fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(30, 300)) fig.tight_layout() for i in range(cols): for j,row in data.iterrows(): x_selected = X_train[y_train == j] if len(x_selected)==0: continue 
axs[j][i].imshow(x_selected[random.randint(0, len(x_selected)-1), :, :], cmap=plt.get_cmap("gray")) 
axs[j][i].axis("off") if i == 2: axs[j][i].set_title(str(j)+ "-"+str(row["ClassId"])) num_of_samples.append(len(x_selected)) 
 
print(num_of_samples) plt.figure(figsize=(12, 4)) plt.bar(range(0, num_classes), num_of_samples) plt.title("Distribution of the training dataset") 
plt.xlabel("Class number") plt.ylabel("Number of images") plt.show() 
 
 
############################### PREPROCESSING THE IMAGES 
 
def grayscale(img): 
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) return img 
 
 
def equalize(img): img = cv2.equalizeHist(img) return img 
 
 
def preprocessing(img): img = grayscale(img) img = equalize(img) 
img = img / 255 # image normalization return img 
 
 
X_train = np.array(list(map(preprocessing, X_train))) 
X_validation = np.array(list(map(preprocessing, X_validation))) 
X_test = np.array(list(map(preprocessing, X_test))) 
 
### reshape data into channel 1 
X_train=X_train.reshape(-1,32,32,1) 
X_validation=X_validation.reshape(-1,32,32,1) 
X_test=X_test.reshape(-1,32,32,1) 
 
#Augmentation of  images 
dataGen = ImageDataGenerator(width_shift_range=0.1, 
height_shift_range=0.1, zoom_range=0.2, shear_range=0.1, rotation_range=10) dataGen.fit(X_train) 
batches = dataGen.flow(X_train, y_train,batch_size=20) 
X_batch, y_batch = next(batches) 
 
y_train = to_categorical(y_train, noOfClasses) y_validation = to_categorical(y_validation, noOfClasses) y_test = to_categorical(y_test, noOfClasses) 
 
 
#CNN Model 
def seq_Model(): no_Of_Filters = 60 size_of_Filter = (5, 5) size_of_Filter2 = (3, 3) 
size_of_pool = (2, 2) no_Of_Nodes = 500 model = Sequential() 
model.add((Conv2D(no_Of_Filters, size_of_Filter, input_shape=(32, 32, 1), activation='relu'))) 
model.add((Conv2D(no_Of_Filters, size_of_Filter, activation='relu'))) model.add(MaxPooling2D(pool_size=size_of_pool)) 
 
model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu'))) model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu'))) 
model.add(MaxPooling2D(pool_size=size_of_pool)) model.add(Dropout(0.5)) 
 
model.add(Flatten()) 
model.add(Dense(no_Of_Nodes, activation='relu')) model.add(Dropout(0.5)) 
model.add(Dense(noOfClasses, activation='softmax')) 
model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy']) return model 
 
model = seq_Model() 
print(model.summary()) ##TRAIN## 
history=model.fit(dataGen.flow(X_train,y_train,batch_size=batch_size_val),steps_per_epoch =steps_per_epoch_val,epochs=epochs_val,validation_data=(X_validation,y_validation),shuff le=1) 
 
##Plot Graph## plt.figure(1) plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.legend(['training','validation']) 
plt.title('loss') plt.xlabel('epoch') plt.figure(2) plt.plot(history.history['accuracy']) plt.plot(history.history['val_accuracy']) plt.legend(['training','validation']) plt.title('Acurracy') plt.xlabel('epoch') plt.show() #model testing 
score =model.evaluate(X_test,y_test,verbose=0) 
print('Test Score:',score[0]) print('Test Accuracy:',score[1]) 
 
#save model 
model.save('traffif_sign_model.h5') 
 
from sklearn.metrics import confusion_matrix from tensorflow import keras import seaborn as sn 
model=keras.models.load_model('traffif_sign_model.h5')      # load model from directory #####Confusion matrix code#### y_pred = model.predict(X_test) 
y_pred = np.argmax(y_pred, axis=1) 
 
cm=confusion_matrix(Y_tests,y_pred)     # confusion matrix 
plt.figure(figsize=(10,7)) 
sn.heatmap(cm, annot=True,cmap='Blues', fmt='g') 
plt.xlabel('Predicted') plt.ylabel('Truth') 
plt.savefig('confusionmatrix.png', dpi=300, bbox_inches='tight') 
